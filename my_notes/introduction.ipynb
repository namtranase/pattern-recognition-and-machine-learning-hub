{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History\n",
    "Some basic concepts of Pattern Problem:\n",
    "- Supervised learning: Classification, Regression\n",
    "- Unsuperviserd learning: Clustering, density estimation, visualization (dimension reduction)\n",
    "- Reinforcement learning\n",
    "\n",
    "Some important tool use through the book:\n",
    "- probablility theory\n",
    "- decision theory\n",
    "- information theory\n",
    "\n",
    "\n",
    "# Polynomial Curve Fitting\n",
    "\n",
    "  ![kernel_2.png](./pictures/chapter1_1.png)\n",
    "             \n",
    " - Using RMS errors to validate the generation of model\n",
    " - Watch the over-fitting problem! (Using the bayansian, maximum likelihood to solve)\n",
    " - Introducing the regularization, in order to discourage the coefficients from reaching large values\n",
    "  => quadratic regularizer (`ridge regression`), in neural networks this approach is known as weight decay.\n",
    " \n",
    " Summary of this sub_chapter: When deal with `Polynomial Curve`. We much to choose degree carefully. Using weight decay for later convinient. Using valid set and error measument proper for the better model!\n",
    " \n",
    " => This book is all about the prob!!!\n",
    "\n",
    "# Probability Theory\n",
    "A key concept in the field of pattern recognition is that of uncertainty.\n",
    "=> Probability theory provides a consistent framework for the _quantification and manipulation_ of uncertainty.\n",
    "We have two random variables $X, x_{i,..M}$ and $Y, y_{j,..L}$ Some basic equations:\n",
    "- Joint probability: $P(X=x_i, Y=y_j)$ \n",
    " => `Sum rule`, and _marginal probability_ : $p(X = x_i) = \\sum_{j=1}^{L}p(X = x_i, Y = y_j)$\n",
    " \n",
    "- Condition probability: $P(Y=y_j| X=x_i)$ \n",
    "=> `Product rule`: $p(X = x_i , Y = y_j) = p(Y = y_j|X = x_i)p(X = x_i)$ (some trick calculate here)\n",
    "\n",
    "From two rule above, we have the bayes theorem, which used through this book:\n",
    "               $p(Y |X) = \\frac{p(X|Y )p(Y )}{p(X)}$        and        $p(X) = \\sum{p(X|Y )p(Y )}$ \n",
    "\n",
    "Remember the `prior probability` (have before) and `posterior probability` (have after)\n",
    "\n",
    "## Probability densities\n",
    " $p(x)$ is called the probability density over $x$ where:  $p(x ∈ (a, b)) = \\int_{a}^{b}{p(x) dx}$ \n",
    "                                                         \n",
    "## Expectations and covariations\n",
    "The average value of some function $f(x)$ under a probability distribution $p(x)$ is called the expectation of $f(x)$, defined by $E[f] = \\int{p(x)f (x)dx}$ and will be denoted by $E[f]$. \n",
    "\n",
    "The variance of $f(x)$ is defined by $var[f] = E[(f(x) − E[f(x)])^2]$ and provides a measure of how much variability there is in $f(x)$ around its mean value $E[f(x)]$. If x and y are independent, then their covariance vanishes.\n",
    "## Bayensian probabilities\n",
    "Formular, with prior probability distribution $p(w)$.\n",
    "                           \n",
    "                           $p(w|D) = \\frac{p(D|w)p(w)}{p(D)}$\n",
    "    \n",
    "- This allows us to evaluate the uncertainty in w after we have observed $D$ in the form\n",
    "of the posterior probability $p(w|D)$.\n",
    "- The quantity $p(D|w)$ on the right-hand side of Bayes’ theorem is evaluated for the observed data set D and can be viewed as a function of the parameter vector $w$ => `likelihood function`\n",
    "\n",
    "When have the likelihood, the we defined Bayes as:\n",
    "\n",
    "                               $posterior ∝ likelihood × prior$\n",
    "=> And the likelihood function $p(D|w)$  \n",
    "\n",
    "A widely used frequentist estimator is `maximum likelihood`, in which w is set to the value that maximizes the likelihood function $p(D|w)$. \n",
    "\n",
    "**There has been much controversy and debate associated with the relative mer-\n",
    "its of the frequentist and Bayesian paradigms** _noninformative priors_ (when the chosing of prior is difficult)\n",
    "=> Bayesian methods based on poor choices of prior can give poor results with high\n",
    "confidence.\n",
    "Some extra material: sampling methods, such as Markov chain Monte Carlo\n",
    "\n",
    "## The Gaussian distribution\n",
    "The most important probability distributions for continuous variables:\n",
    "\n",
    " ![chapter1_2.png](./pictures/chapter1_2.png) \n",
    "- Mean = $\\mu$, the square root of the variance, given by $σ$, is called the standard deviation. And $β = 1/σ^2$ , is called the precision.\n",
    "\n",
    "Gaussian distribution defined over a D-dimensional: \n",
    "\n",
    "![chapter1_3.png](./pictures/chapter1_3.png) \n",
    "\n",
    "- Where the D-dimensional vector $μ$ is called the mean, the $D × D$ matrix $Σ$ is called\n",
    "the covariance.\n",
    "\n",
    "When viewed as a function of $μ$ and $σ^2$ , this is the likelihood function for the Gaus-\n",
    "sian for independent and identically distributed dataset $\\textbf{x}$ :\n",
    "\n",
    "![chapter1_4.png](./pictures/chapter1_4.png) \n",
    "- we shall determine values for the unknown parameters $μ$ and $σ^2$ in the Gaussian by maximizing the likelihood function. In practice, it is more convenient to maximize the log of the likelihood function.\n",
    "\n",
    "Apply logarit, we have:\n",
    "![chapter1_5.png](./pictures/chapter1_5.png) \n",
    "\n",
    "- Maximizing above equation with respect to $μ$, we obtain the maximum likelihood solution\n",
    "given by $\\mu_{ML} = \\frac{1}{N}\\sum_{n=1}^{N}x_n$ => which is the sample mean!!!.\n",
    "- Similarly, maximizing with respect to $σ^2$ is $\\sigma_{ML}^{2} = \\frac{1}{N}\\sum_{n=1}^{N}(x_n - \\mu_{ML})^2$  \n",
    "\n",
    "*But there are problem with maximum likelihood*: systematically underestimates the variance of the distribution. This is an example of a phenomenon called bias and is related to the problem of over-fitting encountered in the context of polynomial curve fitting.\n",
    "\n",
    "Sumary: We know the most important distribution for continue variables _Gauss_. How to measure mean and variation. The distribution is still true for vector $\\textbf{x}$ (element of $\\textbf{x}$ independency). How to calculate the maximum likelihood from this distrubition, and the problem with _variation-bias_.\n",
    "\n",
    "##  Curve fitting re-visited\n",
    "\n",
    "Example given by: $p(t|x, w, β) = N(t|y(x, w), β^{-1}$ \n",
    "\n",
    " ![chapter1_6.png](./pictures/chapter1_6.png) \n",
    " \n",
    " We cal the maximum likelihood (ln version):\n",
    "  ![chapter1_7.png](./pictures/chapter1_7.png)\n",
    "  \n",
    "  Using the results of maximum likelihood above, we can calculate the $w_{ML}$ and $β_{ML}$.\n",
    "  => Having determined the parameters w and β, we can now make predictions for new values of x. Because we now have a probabilistic model, these are expressed in terms of the predictive distribution that gives the probability distribution over t, rather than simply a point estimate.\n",
    "  \n",
    "  From these things, we have introduction of _maximum posterior_:\n",
    "    ![chapter1_8.png](./pictures/chapter1_8.png) \n",
    "  - We can now determine w by finding the most probable value of w given the data, in other words by maximizing the posterior distribution.\n",
    "## Bayesian curve fitting\n",
    "Till now, we still need making a point estimate of $w$ and so this does not yet amount to a Bayesian treatment. Trying to fully Bayesian approach!!! => that we integrate over all values of $w$.\n",
    "\n",
    "The new t is predict by distribution (so it not anymore depend on $w$):\n",
    " ![chapter1_9.png](./pictures/chapter1_9.png) \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#  Model selection\n",
    "Introducing the _cross_validation_ method\n",
    "![chapter1_10.png](./pictures/chapter1_10.png)\n",
    "  \n",
    "# The curse of Dimensionality\n",
    "Assume we have thress class, and each datapoint has 12 dimesions. The figure below is a naive approach to classify classes. By using divided cells.\n",
    "![chapter1_11.png](./pictures/chapter1_11.png)\n",
    "  \n",
    "But the problem occurs when the dimension increase => the cells are increase exponential.![chapter1_12.png](./pictures/chapter1_12.png)\n",
    "\n",
    "Introducing the `manifold` technique.\n",
    "\n",
    "# Decision Theory\n",
    "Link: [Decision Theory explained](https://www.youtube.com/watch?v=KYRAO8f5rXA&ab_channel=mathematicalmonk)\n",
    "Using Probability theory to deal with quantifying and manipulating uncertainty. Combind this Decision theory to => make optimal decisions in situations involving uncertainty.\n",
    "\n",
    "## Minimizing the misclassification rate\n",
    "![chapter1_13.png](./pictures/chapter1_13.png)\n",
    "\n",
    "Consider $C_k$ -> $R_k$ (decision regions). $R_k$ must be continuous but can have disjoint points (these points are missclass).\n",
    "\n",
    "So the optimal decision rule is minimize the $p$ mistake:\n",
    "                      $p(mistake) = \\int_{R1}{p(x, C_2)dx} \\int_{R2}{p(x, C_1)dx}$\n",
    "Choose the decision with $p(mistake)$ as small as possible!!!\n",
    "\n",
    "Another choise is we have $p(x, C_k ) = p(C_k |x)p(x)$ based on the product rule,  $p(x)$ is common\n",
    "=> we can restate this result as saying that the minimum probability of making a mistake is obtained if each value of x is assigned to the class for which the `posterior probability` $p(C_k |x)$ is largest.\n",
    "\n",
    "## Minimizing the expected loss\n",
    "Introduction of loss function or cost function.\n",
    "Assume we have point x, which belong to the $C_k$, but is predicted to $C_j$. The loss function is defined by: $L_{jk}, L_{jk}$ belong to $L_{matrix}$\n",
    "\n",
    "For a given input vector $x$, our uncertainty in the true class is expressed through the joint probability distribution $p(x, C_k)$ and so we seek instead to minimize the average loss, where the\n",
    "average is computed with respect to this distribution, which is given by:\n",
    "![chapter1_14.png](./pictures/chapter1_14.png)\n",
    " \n",
    " Each $x$ can be assigned to one of regions $R_j$\n",
    " => Minimize above loss function => Minimize: $\\sum_{k} L_{kj}p(x, C_k)$.\n",
    " Using the product rule: $p(x, C_k) = p(C_k|x)p(x)$, p(x) is common factor can be eliminate\n",
    " => trivial problem when we know the posterior class probabilities $p(C_k|x)$.\n",
    " \n",
    "## The reject option\n",
    "Example: In our hypothetical medical illustration, it may be appropriate to use an automatic system to classify those X-ray images for which there is little doubt as to the correct class, while leaving a human expert to classify the more ambiguous cases.\n",
    "\n",
    "Introducing the threshold $θ$ where the posterior class probabilities $p(C_k|x)$ is less than or equal to $\\theta$.\n",
    "![chapter1_15.png](./pictures/chapter1_15.png) \n",
    "\n",
    "## Inference and decision\n",
    "We devide classification problem to 2 stages: \n",
    "- Inference stage: Use training data to learn a model for $p(C_k|x)$ \n",
    "- Decision: Use this posterior prob to classify\n",
    "Another choice is using discriminant function (not using prob)\n",
    "\n",
    "Some advantages when using prob:\n",
    "- Minimizing risk\n",
    "- Reject option\n",
    "- Compensating for class priors\n",
    "- Combining models\n",
    "\n",
    "## Loss functions for regression\n",
    "Comback to the regression problems. We defined the loss function $L(t, y(x))$.\n",
    "The expected value of $L$ is:\n",
    "![chapter1_16.png](./pictures/chapter1_16.png) \n",
    "\n",
    "# Information Theory\n",
    "[Classic series](https://www.youtube.com/watch?v=2s3aJfRr9gE&list=PLSQl0a2vh4HC9lvrBhVt4UUkhzpp3N5_x&ab_channel=KhanAcademyLabs)\n",
    "[Intuative link](https://towardsdatascience.com/what-is-the-information-in-information-theory-d916250e4899)\n",
    "- We consider a discrete variable $x$, the information is recieved when we observe a specific value for this var.\n",
    "=> The amount of information can be viewed as the _degree of surprise_ on learning the value of $x$. \n",
    "=> The more we don't know about the value, the more information $x$ keep.\n",
    "\n",
    "- Variable $x$ has prob $p(x)$, we have the function $h(x)$ express the information content. If we have x, y independent,\n",
    "so that $h(x, y) = h(x) + h(y)$, also has $p(x, y) = p(x)p(y)$.\n",
    "=> **h(x)** should return the amount of information contained in the event **x** which is high for lower probability and low for high probability events.\n",
    "$h(x) = -log_{2} p(x)$ \n",
    "- With the multiple random variables, the average amout of information is taking by the E of h(x) respect to dis $p(x)$:\n",
    "![chapter1_17.png](./pictures/chapter1_17.png) => This is entropy.\n",
    "\n",
    "## Relative entropy and mutual information\n",
    "Keep updating...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
